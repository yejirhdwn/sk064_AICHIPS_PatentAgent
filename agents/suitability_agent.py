"""
Sustainability Score Agent with LLM-as-a-Judge
- ë…ì°½ì„± + ì‹œì¥ì„± ì ìˆ˜ë¥¼ LLMì´ ë¶„ì„í•˜ì—¬ ìµœì¢… í‰ê°€
- GPT-4ê°€ ì ìˆ˜ì˜ ì˜ë¯¸ë¥¼ í•´ì„í•˜ê³  ì¢…í•©ì ì¸ íŒë‹¨ ìˆ˜í–‰
"""

from __future__ import annotations
import os, json
from typing import Any, Dict, Optional
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

try:
    from openai import OpenAI
    _OPENAI_OK = True
except Exception:
    _OPENAI_OK = False
    print("âš ï¸ OpenAI not available. Install: pip install openai")

load_dotenv()


# ===== Configuration =====
class ScoringConfig:
    """ì ìˆ˜ ì‚°ì • ì„¤ì •"""
    ORIGINALITY_WEIGHT = 0.55
    MARKET_WEIGHT = 0.45
    ORIGINALITY_MIN = 0.75
    ORIGINALITY_MAX = 1.0
    
    GRADE_THRESHOLDS = {
        "S": 0.85, "A": 0.70, "B": 0.55, "C": 0.40, "D": 0.0
    }


# ===== LLM Judge Prompts =====
JUDGE_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ íŠ¹í—ˆ ê¸°ìˆ ì˜ ì§€ì†ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì—­í• :**
- ë…ì°½ì„±(Originality)ê³¼ ì‹œì¥ì„±(Market) ì ìˆ˜ë¥¼ ì¢…í•© ë¶„ì„
- ê¸°ìˆ ì˜ ì¥ê¸°ì  ìƒì¡´ ê°€ëŠ¥ì„±ê³¼ íˆ¬ì ê°€ì¹˜ íŒë‹¨
- ì ìˆ˜ ì´ë©´ì˜ ì˜ë¯¸ë¥¼ í•´ì„í•˜ê³  êµ¬ì²´ì ì¸ ê·¼ê±° ì œì‹œ

**í‰ê°€ ê¸°ì¤€:**
1. ê¸°ìˆ ì  ë…ì°½ì„±: íŠ¹í—ˆì˜ ì‹ ê·œì„±, ì°¨ë³„ì„±, ê¸°ìˆ ì  ë‚œì´ë„
2. ì‹œì¥ ì ì¬ë ¥: ì‹œì¥ ê·œëª¨, ì„±ì¥ ê°€ëŠ¥ì„±, ìƒì—…í™” ì¤€ë¹„ë„
3. ì§€ì†ê°€ëŠ¥ì„±: ê¸°ìˆ  ìˆ˜ëª…, ê²½ìŸë ¥ ì§€ì†ì„±, íˆ¬ì ë¦¬ìŠ¤í¬

**ì‘ë‹µ í˜•ì‹:**
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "sustainability_grade": "S/A/B/C/D ì¤‘ í•˜ë‚˜",
  "confidence_score": 0.0-1.0,
  "key_strengths": ["ê°•ì 1", "ê°•ì 2", "ê°•ì 3"],
  "key_weaknesses": ["ì•½ì 1", "ì•½ì 2"],
  "investment_recommendation": "ì¶”ì²œ/ë³´ë¥˜/ë¹„ì¶”ì²œ ì¤‘ í•˜ë‚˜",
  "risk_level": "ë‚®ìŒ/ë³´í†µ/ë†’ìŒ ì¤‘ í•˜ë‚˜",
  "reasoning": "ì¢…í•©ì ì¸ í‰ê°€ ê·¼ê±° (2-3ë¬¸ì¥)",
  "strategic_advice": "ì „ëµì  ì¡°ì–¸ (2-3ë¬¸ì¥)"
}
"""


def _create_judge_prompt(
    tech_name: str,
    originality_score: float,
    market_score: float,
    calculated_grade: str,
    market_details: Optional[Dict] = None
) -> str:
    """LLM Judgeë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    prompt = f"""**ê¸°ìˆ ëª…**: {tech_name}

**ì ìˆ˜ ì •ë³´:**
- ë…ì°½ì„± ì ìˆ˜: {originality_score:.4f} (0~1 ë²”ìœ„, ë†’ì„ìˆ˜ë¡ ì‹ ê·œì„± ë†’ìŒ)
- ì‹œì¥ì„± ì ìˆ˜: {market_score:.4f} (0~1 ë²”ìœ„, ë†’ì„ìˆ˜ë¡ ì‹œì¥ ì ì¬ë ¥ ë†’ìŒ)
- ê³„ì‚°ëœ ë“±ê¸‰: {calculated_grade}

**ë…ì°½ì„± ì ìˆ˜ í•´ì„:**
- 0.90+: ë§¤ìš° ë†’ì€ ê¸°ìˆ ì  ë…ì°½ì„± (í˜ì‹ ì )
- 0.80-0.90: ë†’ì€ ê¸°ìˆ ì  ë…ì°½ì„± (ì°¨ë³„í™”ë¨)
- 0.70-0.80: ì–‘í˜¸í•œ ê¸°ìˆ ì  ë…ì°½ì„±
- 0.70 ë¯¸ë§Œ: ë³´í†µ ìˆ˜ì¤€ì˜ ë…ì°½ì„±

**ì‹œì¥ì„± ì ìˆ˜ í•´ì„:**
- 0.75+: ìš°ìˆ˜í•œ ì‹œì¥ ì ì¬ë ¥ (ëŒ€ê·œëª¨ ì‹œì¥)
- 0.55-0.75: ì–‘í˜¸í•œ ì‹œì¥ ì ì¬ë ¥
- 0.35-0.55: ë³´í†µ ìˆ˜ì¤€ì˜ ì‹œì¥ ì ì¬ë ¥
- 0.35 ë¯¸ë§Œ: ì œí•œì ì¸ ì‹œì¥ ì ì¬ë ¥
"""
    
    if market_details:
        prompt += f"""
**ì‹œì¥ ì„¸ë¶€ ì •ë³´:**
- ì‹œì¥ ê·œëª¨: {market_details.get('market_size_score', 'N/A')}
- ì„±ì¥ ì ì¬ë ¥: {market_details.get('growth_potential_score', 'N/A')}
- ìƒì—…í™” ì¤€ë¹„ë„: {market_details.get('commercialization_readiness', 'N/A')}
"""
    
    prompt += """
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ê¸°ìˆ ì˜ ì§€ì†ê°€ëŠ¥ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
ë‹¨ìˆœíˆ ì ìˆ˜ë§Œ ë³´ì§€ ë§ê³ , ì ìˆ˜ ì¡°í•©ì´ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì„¸ìš”.

ì˜ˆë¥¼ ë“¤ì–´:
- ë…ì°½ì„±ì€ ë†’ì§€ë§Œ ì‹œì¥ì„±ì´ ë‚®ë‹¤ë©´? â†’ í‹ˆìƒˆ ì‹œì¥ ì „ëµ í•„ìš”
- ì‹œì¥ì„±ì€ ë†’ì§€ë§Œ ë…ì°½ì„±ì´ ë‚®ë‹¤ë©´? â†’ ê²½ìŸ ë¦¬ìŠ¤í¬ ë†’ìŒ
- ë‘˜ ë‹¤ ë†’ë‹¤ë©´? â†’ ê°•ë ¥ íˆ¬ì ì¶”ì²œ
- ë‘˜ ë‹¤ ë‚®ë‹¤ë©´? â†’ ì¬ê²€í†  í•„ìš”

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
"""
    
    return prompt


# ===== Main Agent =====
class SustainabilityScoreAgent:
    """
    LLM-as-a-Judge ê¸°ë°˜ ì§€ì†ê°€ëŠ¥ì„± í‰ê°€ Agent
    
    1ì°¨: ìˆ˜ì‹ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
    2ì°¨: LLMì´ ì ìˆ˜ë¥¼ í•´ì„í•˜ê³  ìµœì¢… íŒë‹¨
    """
    
    def __init__(
        self, 
        tech_name: str,
        output_dir: str = "./output/sustainability",
        use_llm_judge: bool = True
    ):
        self.tech_name = tech_name
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.use_llm_judge = use_llm_judge and _OPENAI_OK
        
        if self.use_llm_judge:
            self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            self.model = "gpt-4o-mini"  # or "gpt-4o"
    
    def calculate_sustainability(
        self,
        originality_score: float,
        market_score: float,
        market_size_score: Optional[float] = None,
        growth_potential_score: Optional[float] = None,
        commercialization_readiness: Optional[float] = None,
        normalize_originality: bool = True
    ) -> Dict[str, Any]:
        """
        ì§€ì†ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚° + LLM í‰ê°€
        """
        print("=" * 80)
        print(f"ğŸŒ± Sustainability Score Calculation: {self.tech_name}")
        print("=" * 80)
        
        # ì…ë ¥ ê²€ì¦
        if not (0 <= originality_score <= 1):
            raise ValueError(f"originality_score must be in [0, 1], got {originality_score}")
        if not (0 <= market_score <= 1):
            raise ValueError(f"market_score must be in [0, 1], got {market_score}")
        
        print(f"ğŸ“Š Input Scores:")
        print(f"   - Originality: {originality_score:.4f}")
        print(f"   - Market: {market_score:.4f}")
        
        # ===== Step 1: ìˆ˜ì‹ ê¸°ë°˜ ê³„ì‚° =====
        if normalize_originality:
            originality_normalized = self._normalize_originality(originality_score)
        else:
            originality_normalized = originality_score
        
        calculated_score = self._calculate_score(originality_normalized, market_score)
        calculated_grade = self._determine_grade(calculated_score)
        
        breakdown = {
            "originality_raw": originality_score,
            "originality_normalized": originality_normalized,
            "originality_weighted": round(originality_normalized * ScoringConfig.ORIGINALITY_WEIGHT, 4),
            "market_score": market_score,
            "market_weighted": round(market_score * ScoringConfig.MARKET_WEIGHT, 4),
            "calculated_score": calculated_score,
            "calculated_grade": calculated_grade
        }
        
        print(f"\nğŸ“ Calculated Metrics:")
        print(f"   - Score: {calculated_score:.4f}")
        print(f"   - Grade: {calculated_grade}")
        
        # ===== Step 2: LLM Judge í‰ê°€ =====
        llm_evaluation = None
        final_grade = calculated_grade
        final_score = calculated_score
        
        if self.use_llm_judge:
            print(f"\nğŸ¤– LLM Judge Evaluation...")
            
            market_details = {
                "market_size_score": market_size_score,
                "growth_potential_score": growth_potential_score,
                "commercialization_readiness": commercialization_readiness
            }
            
            llm_evaluation = self._llm_judge_evaluation(
                originality_score,
                market_score,
                calculated_grade,
                market_details if any(market_details.values()) else None
            )
            
            if llm_evaluation:
                final_grade = llm_evaluation.get("sustainability_grade", calculated_grade)
                print(f"   âœ… LLM Grade: {final_grade}")
                print(f"   âœ… Confidence: {llm_evaluation.get('confidence_score', 0):.2f}")
                print(f"   âœ… Recommendation: {llm_evaluation.get('investment_recommendation', 'N/A')}")
                print(f"   âœ… Risk Level: {llm_evaluation.get('risk_level', 'N/A')}")
        
        # ===== Step 3: ì¢…í•© ìš”ì•½ ìƒì„± =====
        summary = self._generate_summary(
            originality_score, 
            market_score, 
            final_score, 
            final_grade,
            llm_evaluation
        )
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            "tech_name": self.tech_name,
            "originality_score": originality_score,
            "market_score": market_score,
            "calculated_score": calculated_score,
            "calculated_grade": calculated_grade,
            "final_grade": final_grade,
            "sustainability_score": final_score,
            "sustainability_grade": final_grade,
            "score_breakdown": breakdown,
            "llm_evaluation": llm_evaluation,
            "evaluation_summary": summary
        }
        
        # ì„¸ë¶€ ì ìˆ˜ ì¶”ê°€
        if market_size_score is not None:
            result["market_size_score"] = market_size_score
        if growth_potential_score is not None:
            result["growth_potential_score"] = growth_potential_score
        if commercialization_readiness is not None:
            result["commercialization_readiness"] = commercialization_readiness
        
        # ê²°ê³¼ ì €ì¥
        output_path = self._save_result(result)
        result["sustainability_output_path"] = str(output_path)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ¯ Final Evaluation Result")
        print("=" * 80)
        print(f"âœ… Grade: {final_grade}")
        print(f"   - Calculated: {calculated_grade} ({calculated_score:.4f})")
        if llm_evaluation:
            print(f"   - LLM Assessed: {final_grade}")
            print(f"\nğŸ’¡ Key Strengths:")
            for strength in llm_evaluation.get("key_strengths", []):
                print(f"   â€¢ {strength}")
            print(f"\nâš ï¸ Key Weaknesses:")
            for weakness in llm_evaluation.get("key_weaknesses", []):
                print(f"   â€¢ {weakness}")
            print(f"\nğŸ¯ Investment: {llm_evaluation.get('investment_recommendation', 'N/A')}")
            print(f"ğŸ“Š Risk Level: {llm_evaluation.get('risk_level', 'N/A')}")
        print(f"\nğŸ“ {summary}")
        print(f"\nğŸ’¾ Saved to: {output_path}")
        print("=" * 80)
        
        return result
    
    def _llm_judge_evaluation(
        self,
        originality: float,
        market: float,
        calculated_grade: str,
        market_details: Optional[Dict] = None
    ) -> Optional[Dict[str, Any]]:
        """LLMì„ Judgeë¡œ ì‚¬ìš©í•˜ì—¬ í‰ê°€"""
        if not self.use_llm_judge:
            return None
        
        try:
            prompt = _create_judge_prompt(
                self.tech_name,
                originality,
                market,
                calculated_grade,
                market_details
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": JUDGE_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            evaluation = json.loads(response.choices[0].message.content)
            return evaluation
            
        except Exception as e:
            print(f"   âš ï¸ LLM evaluation failed: {e}")
            return None
    
    def _normalize_originality(self, score: float) -> float:
        """ë…ì°½ì„± ì ìˆ˜ ì •ê·œí™”"""
        if score >= ScoringConfig.ORIGINALITY_MAX:
            return 1.0
        if score <= ScoringConfig.ORIGINALITY_MIN:
            return 0.0
        normalized = (score - ScoringConfig.ORIGINALITY_MIN) / \
                     (ScoringConfig.ORIGINALITY_MAX - ScoringConfig.ORIGINALITY_MIN)
        return max(0.0, min(1.0, normalized))
    
    def _calculate_score(self, originality_normalized: float, market: float) -> float:
        """ì§€ì†ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°"""
        sustainability = (
            originality_normalized * ScoringConfig.ORIGINALITY_WEIGHT +
            market * ScoringConfig.MARKET_WEIGHT
        )
        return round(sustainability, 4)
    
    def _determine_grade(self, score: float) -> str:
        """ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ ê²°ì •"""
        for grade, threshold in ScoringConfig.GRADE_THRESHOLDS.items():
            if score >= threshold:
                return grade
        return "D"
    
    def _generate_summary(
        self, 
        originality: float, 
        market: float, 
        score: float, 
        grade: str,
        llm_eval: Optional[Dict] = None
    ) -> str:
        """ì¢…í•© í‰ê°€ ìš”ì•½ ìƒì„±"""
        if llm_eval and llm_eval.get("reasoning"):
            # LLMì´ ìƒì„±í•œ í‰ê°€ ì‚¬ìš©
            base_summary = f"'{self.tech_name}' ê¸°ìˆ  (ë“±ê¸‰: {grade}, ì ìˆ˜: {score:.2f})"
            reasoning = llm_eval.get("reasoning", "")
            advice = llm_eval.get("strategic_advice", "")
            return f"{base_summary}\n\ní‰ê°€: {reasoning}\n\nì „ëµì  ì¡°ì–¸: {advice}"
        else:
            # ê¸°ë³¸ ìš”ì•½
            if originality >= 0.90:
                orig_eval = "ë§¤ìš° ë†’ì€ ê¸°ìˆ ì  ë…ì°½ì„±"
            elif originality >= 0.80:
                orig_eval = "ë†’ì€ ê¸°ìˆ ì  ë…ì°½ì„±"
            else:
                orig_eval = "ì–‘í˜¸í•œ ê¸°ìˆ ì  ë…ì°½ì„±"
            
            if market >= 0.75:
                market_eval = "ìš°ìˆ˜í•œ ì‹œì¥ ì ì¬ë ¥"
            elif market >= 0.55:
                market_eval = "ì–‘í˜¸í•œ ì‹œì¥ ì ì¬ë ¥"
            else:
                market_eval = "ë³´í†µ ìˆ˜ì¤€ì˜ ì‹œì¥ ì ì¬ë ¥"
            
            return f"'{self.tech_name}' ê¸°ìˆ ì€ {orig_eval}ê³¼ {market_eval}ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ìµœì¢… ë“±ê¸‰ì€ {grade}ì…ë‹ˆë‹¤."
    
    def _save_result(self, result: Dict[str, Any]) -> Path:
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"sustainability_{self.tech_name}_{timestamp}.json"
        output_path = self.output_dir / filename
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        return output_path


# ===== CLI =====
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Sustainability Agent with LLM Judge")
    parser.add_argument("tech_name", type=str, help="ê¸°ìˆ  í‚¤ì›Œë“œ")
    parser.add_argument("--originality", type=float, required=True, help="ë…ì°½ì„± ì ìˆ˜")
    parser.add_argument("--market", type=float, required=True, help="ì‹œì¥ì„± ì ìˆ˜")
    parser.add_argument("--no-llm", action="store_true", help="LLM Judge ë¹„í™œì„±í™”")
    args = parser.parse_args()
    
    agent = SustainabilityScoreAgent(
        tech_name=args.tech_name,
        use_llm_judge=not args.no_llm
    )
    
    result = agent.calculate_sustainability(
        originality_score=args.originality,
        market_score=args.market
    )
    
    print(f"\nâœ… Grade: {result['sustainability_grade']}")


__all__ = ["SustainabilityScoreAgent"]