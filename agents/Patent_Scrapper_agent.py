# =========================================================
# Patent_Scrapper_agent.py
# =========================================================

import os
import json
import requests
from dotenv import load_dotenv

# ---------- í™˜ê²½ ë³€ìˆ˜ ----------
load_dotenv()
SERPAPI_KEY = os.getenv("SERPAPI_KEY")
BASE_URL = "https://serpapi.com/search.json"


# ---------- ìœ í‹¸ ----------
def clamp_num(n: int) -> int:
    """SerpAPI google_patents: numì€ 10~100 ë²”ìœ„"""
    return max(10, min(int(n), 100))

def clamp_page(p: int) -> int:
    """í˜„ì¬ ì—”ì§„ì€ pageë¥¼ 1ë¶€í„° ìš”êµ¬"""
    return max(1, int(p))

def prepared_url(params):
    """ìš”ì²­ URL ë””ë²„ê¹…ìš©"""
    from requests import Request
    return Request("GET", BASE_URL, params=params).prepare().url

def normalize_item(it):
    """organic_resultsë¥¼ í‘œì¤€ í•„ë“œë¡œ ë³€í™˜"""
    return {
        "title": it.get("title"),
        "abstract": it.get("snippet"),
        "patent_id": it.get("patent_id"),
        "publication_number": it.get("publication_number"),
        "publication_date": it.get("publication_date"),
        "filing_date": it.get("filing_date"),
        "priority_date": it.get("priority_date"),
        "assignee": it.get("assignee"),
        "inventor": it.get("inventor"),
        "link": it.get("patent_link"),
        "pdf": it.get("pdf"),
    }


# ---------- ë©”ì¸ í•¨ìˆ˜ ----------
def search_google_patents(
    query: str,
    num: int = 10,
    page: int = 1,
    country: str | None = None,
    language: str | None = None,
    status: str | None = None,
    ptype: str | None = "PATENT",
):
    """Google Patentsì—ì„œ íŠ¹í—ˆ ê²€ìƒ‰"""
    if not SERPAPI_KEY:
        return {"error": "SERPAPI_KEY not set."}

    params = {
        "engine": "google_patents",
        "q": query,
        "num": clamp_num(num),
        "page": clamp_page(page),
        "api_key": SERPAPI_KEY,
    }
    if country:  params["country"]  = country
    if language: params["language"] = language
    if status:   params["status"]   = status
    if ptype:    params["type"]     = ptype

    url = prepared_url(params)
    r = requests.get(BASE_URL, params=params, timeout=30)
    if r.status_code != 200:
        return {"error": f"SerpAPI {r.status_code}: {r.text}", "serpapi_url": url}

    data = r.json()
    items = data.get("organic_results", [])
    if not items:
        return {"error": "No patents found.", "serpapi_url": url}

    rows = [normalize_item(it) for it in items]
    return {
        "query": query,
        "serpapi_url": url,
        "count": len(rows),
        "items": rows,
        "first_item": rows[0] if rows else {},
    }


# ---------- ì‹¤í–‰ ----------
if __name__ == "__main__":
    query = '(HBM OR "High Bandwidth Memory") (AI OR accelerator OR processor) 2024'
    num = 10
    page = 1
    country = "US,WO,KR,JP,EP"
    language = "ENGLISH,KOREAN"
    status = None
    ptype = "PATENT"

    print(f"ğŸ” Searching Google Patents for: {query}")

    result = search_google_patents(
        query=query,
        num=num,
        page=page,
        country=country,
        language=language,
        status=status,
        ptype=ptype,
    )

    if result.get("error"):
        print("âŒ Error:", result["error"])
        if result.get("serpapi_url"):
            print("Request URL:", result["serpapi_url"])
        raise SystemExit(1)

    print("âœ… Found:", result["count"], "patents")
    print("Request URL:", result["serpapi_url"])

    # ê²°ê³¼ ì €ì¥
    out_path = "hbm_search_output.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ Saved results to: {out_path}")
    print("\n===== [Top Result] =====")
    print(json.dumps(result["first_item"], ensure_ascii=False, indent=2))
