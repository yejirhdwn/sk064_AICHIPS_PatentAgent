"""
Patent-Centric Market Evaluation with Tavily Search Integration
- RAG (ë¡œì»¬ ë¬¸ì„œ) + Tavily (ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰) Hybrid
- ì‹œì¥ ê·œëª¨: íŠ¹í—ˆê°€ ì‹¤ì œ ì ìš© ê°€ëŠ¥í•œ ì„¸ë¶€ ì‹œì¥(SAM) ê¸°ì¤€
- ì„±ì¥ë¥ : CAGR ë˜ëŠ” êµ¬ì²´ì  ì„±ì¥ ìˆ˜ì¹˜
- Tavilyë¡œ ìµœì‹  ì‹œì¥ ë°ì´í„° ë³´ì™„
"""

from __future__ import annotations
import os, json, re
from typing import Any, Dict, List, Optional, TypedDict
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

from pydantic import BaseModel, Field, field_validator

# LangChain / LangGraph
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_community.retrievers import BM25Retriever
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# Tavily Search
from tavily import TavilyClient

load_dotenv(Path(__file__).resolve().parent.parent / ".env")


# ===== State Definition =====
class MarketState(TypedDict, total=False):
    """íŠ¹í—ˆ ì‹œì¥ì„± í‰ê°€ State"""
    tech_name: str
    error: str
    first_item: Dict[str, Any]
    target_patent_id: str
    query: str
    keyterms: List[str]
    retrieved_docs: List[Any]
    web_search_results: List[Dict[str, Any]]
    
    # Scores
    market_size_score: float
    growth_potential_score: float
    commercialization_readiness: float
    market_score: float
    
    # Outputs
    patent_id: str
    patent_title: str
    application_domains: List[str]
    commercialization_potential: str
    market_rationale: str
    demand_signals: List[str]
    sources: List[str]
    market_output_path: str


# ===== Schema =====
class _KeytermsSchema(BaseModel):
    keyterms: List[str] = Field(..., description="abstractì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œ(ëŒ€í‘œì–´, 3~8ê°œ)")


class _MarketSchema(BaseModel):
    tech_name: str
    patent_id: str
    patent_title: str
    
    # ì •ëŸ‰ì  ì ìˆ˜
    market_size_score: float = Field(..., ge=0.0, le=0.4, description="ì‹¤ì œ ì ìš© ê°€ëŠ¥ ì‹œì¥(SAM) ê¸°ë°˜")
    growth_potential_score: float = Field(..., ge=0.0, le=0.3, description="CAGR ë˜ëŠ” êµ¬ì²´ì  ì„±ì¥ë¥ ")
    commercialization_readiness: float = Field(..., ge=0.0, le=0.3, description="ìƒìš©í™” ì¤€ë¹„ë„")
    market_score: float = Field(..., ge=0.0, le=1.0, description="ì´ì ")
    
    # ì •ì„±ì  í‰ê°€
    application_domains: List[str] = Field(..., description="ì ìš© ê°€ëŠ¥í•œ ì‚°ì—…/ì œí’ˆêµ° (ìµœëŒ€ 5ê°œ)")
    commercialization_potential: str = Field(..., description="High/Medium/Low")
    market_rationale: str = Field(..., description="'ì´ íŠ¹í—ˆ(patent_id)ëŠ” ...' í˜•ì‹, 5~7ë¬¸ì¥")
    demand_signals: List[str] = Field(default_factory=list, description="ì‹œì¥ ìˆ˜ìš” ì‹ í˜¸ (ìµœëŒ€ 5ê°œ)")
    
    # ì¶œì²˜ (ì½”ë“œì—ì„œ ìë™ ë®ì–´ì“°ê¸°)
    sources: Optional[List[str]] = None

    @field_validator("commercialization_potential")
    @classmethod
    def _validate_potential(cls, v):
        if v not in ["High", "Medium", "Low"]:
            raise ValueError("Must be High/Medium/Low")
        return v


# ===== Helpers =====
def _extract_keyterms_from_abstract(llm: ChatOpenAI, title: str, abstract: str, max_terms: int = 8) -> List[str]:
    """LLMìœ¼ë¡œ abstractì—ì„œ í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ"""
    system = (
        "ë„ˆëŠ” íŠ¹í—ˆ ê¸°ìˆ  ë¶„ì„ ì „ë¬¸ê°€ë‹¤. "
        "ì œëª©ê³¼ ì´ˆë¡ì—ì„œ í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œ(ëŒ€í‘œì–´)ë§Œ ì¶”ì¶œí•œë‹¤. "
        "íšŒì‚¬ëª…, ì œí’ˆëª…, í˜•ìš©ì‚¬, ì¼ë°˜ì ì¸ ë‹¨ì–´ëŠ” ì œì™¸í•˜ê³  ê¸°ìˆ ì  ê°œë…ë§Œ ì¶”ì¶œ."
    )
    human = (
        "ì œëª©: {title}\n\n"
        "ì´ˆë¡: {abstract}\n\n"
        f"í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œë¥¼ ìµœëŒ€ {max_terms}ê°œ ì¶”ì¶œí•˜ë¼. "
        "JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜: {{\"keyterms\": [\"keyword1\", \"keyword2\", ...]}}"
    )
    
    prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human)])
    chain = prompt | llm.with_structured_output(_KeytermsSchema)

    try:
        result: _KeytermsSchema = chain.invoke({"title": title, "abstract": abstract})
        return [t.strip() for t in result.keyterms if t.strip()][:max_terms]
    except Exception as e:
        print(f"  âš ï¸ Keyterm extraction failed: {e}")
        # Fallback: ë‹¨ìˆœ ì¶”ì¶œ
        text = (abstract or "").lower()
        tokens = re.findall(r"[a-z][a-z0-9\-]{3,}", text)
        return sorted(set(tokens), key=tokens.count, reverse=True)[:max_terms]


def _build_rag_query(tech_name: str, keyterms: List[str]) -> str:
    """RAG ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±"""
    parts = [tech_name] + keyterms[:6] + ["market size", "growth", "industry application"]
    seen = set()
    unique = []
    for p in parts:
        p_lower = p.lower().strip()
        if p_lower and p_lower not in seen:
            unique.append(p.strip())
            seen.add(p_lower)
    return " ".join(unique)


def _build_tavily_queries(tech_name: str, keyterms: List[str]) -> List[str]:
    """Tavily ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ì‹œì¥ ê·œëª¨, CAGR)"""
    queries = []
    
    # 1. ê¸°ìˆ  í‚¤ì›Œë“œ ê¸°ë°˜ ì‹œì¥ ê·œëª¨
    tech_terms = " ".join([tech_name] + keyterms[:3])
    queries.append(f"{tech_terms} market size 2024 2025 billion USD")
    
    # 2. CAGR ë° ì„±ì¥ë¥ 
    queries.append(f"{tech_terms} CAGR growth rate forecast 2024-2028")
    
    # 3. ì‘ìš© ë¶„ì•¼ ì¼ë°˜ ì¿¼ë¦¬
    queries.append(f"{tech_name} application market forecast")
    
    return queries[:3]  # ìµœëŒ€ 3ê°œ ì¿¼ë¦¬


def _collect_sources(rag_docs: List[Document], tavily_results: List[Dict[str, Any]], max_items: int = 8) -> List[str]:
    """RAG + Tavily ì¶œì²˜ ìˆ˜ì§‘"""
    sources = []
    seen = set()
    
    # RAG ë¬¸ì„œ
    for doc in rag_docs:
        src = (doc.metadata or {}).get("source") or (doc.metadata or {}).get("filename")
        if src and src not in seen:
            sources.append(f"[RAG] {src}")
            seen.add(src)
    
    # Tavily ê²°ê³¼
    for result in tavily_results:
        url = result.get("url", "")
        title = result.get("title", "")
        if url and url not in seen:
            display = title[:50] if title else url
            sources.append(f"[Web] {display} ({url})")
            seen.add(url)
        
        if len(sources) >= max_items:
            break
    
    return sources or ["No sources available"]


# ===== Agent =====
class MarketSizeGrowthAgent:
    def __init__(
        self, 
        tech_name: str, 
        patent_info: Dict[str, Any], 
        output_dir: str = "./output/market_evaluation"
    ):
        self.tech_name = tech_name
        self.patent_info = patent_info
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Environment variables
        self.collection = os.getenv("MARKET_COLLECTION", "patent_market_index")
        self.chroma_dir = os.getenv("MARKET_CHROMA_DIR", "./rag/chroma")
        self.embed_model = os.getenv("MARKET_EMBED_MODEL", "bge-m3")
        self.llm_model = os.getenv("MARKET_LLM_MODEL", "gpt-4o-mini")
        api_key = os.getenv("OPENAI_API_KEY")
        tavily_key = os.getenv("TAVILY_API_KEY")

        # VectorDB setup
        self.embeddings = OllamaEmbeddings(model=self.embed_model)
        self.vs = Chroma(
            collection_name=self.collection,
            persist_directory=self.chroma_dir,
            embedding_function=self.embeddings
        )
        self.semantic = self.vs.as_retriever(search_kwargs={"k": 4})

        # BM25 setup
        all_docs = self.vs.get(include=["documents", "metadatas"])
        bm25_docs = [
            Document(page_content=d or "", metadata=m or {}) 
            for d, m in zip(all_docs["documents"], all_docs["metadatas"])
        ]
        self.bm25 = BM25Retriever.from_documents(bm25_docs)
        self.bm25.k = 4

        # LLM
        self.llm = ChatOpenAI(model=self.llm_model, temperature=0, openai_api_key=api_key)
        
        # Tavily Client
        self.tavily = TavilyClient(api_key=tavily_key) if tavily_key else None
        
        self.graph = self._build_graph()

    def _build_graph(self):
        """LangGraph êµ¬ì„±"""
        g = StateGraph(MarketState)
        g.add_node("retrieve_rag", self._node_retrieve_rag)
        g.add_node("retrieve_web", self._node_retrieve_web)
        g.add_node("synthesize", self._node_synthesize)
        
        g.set_entry_point("retrieve_rag")
        g.add_edge("retrieve_rag", "retrieve_web")
        g.add_edge("retrieve_web", "synthesize")
        g.add_edge("synthesize", END)
        
        return g.compile(checkpointer=MemorySaver())

    def _node_retrieve_rag(self, state: MarketState) -> MarketState:
        """RAG ê²€ìƒ‰ ë…¸ë“œ"""
        query = state["query"]
        print(f"ğŸ” [RAG] Retrieving documents for: {query}")
        
        docs_semantic = self.semantic.invoke(query)
        docs_bm25 = self.bm25.invoke(query)  # get_relevant_documents â†’ invoke
        all_docs = (docs_semantic or []) + (docs_bm25 or [])
        
        print(f"  âœ… Retrieved {len(all_docs)} RAG documents")
        state["retrieved_docs"] = all_docs
        return state

    def _node_retrieve_web(self, state: MarketState) -> MarketState:
        """Tavily ì›¹ ê²€ìƒ‰ ë…¸ë“œ"""
        if not self.tavily:
            print("  âš ï¸ Tavily API key not found, skipping web search")
            state["web_search_results"] = []
            return state
        
        tech = state["tech_name"]
        keyterms = state["keyterms"]
        
        # ì‹œì¥ ë°ì´í„° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        queries = _build_tavily_queries(tech, keyterms)
        all_results = []
        
        for q in queries:
            print(f"ğŸŒ [Tavily] Searching: {q}")
            try:
                result = self.tavily.search(query=q, max_results=2)
                all_results.extend(result.get("results", []))
            except Exception as e:
                print(f"  âš ï¸ Tavily search failed for '{q}': {e}")
        
        print(f"  âœ… Retrieved {len(all_results)} web search results")
        state["web_search_results"] = all_results
        return state

    def _node_synthesize(self, state: MarketState) -> MarketState:
        """ì‹œì¥ì„± í‰ê°€ ì¢…í•© ë…¸ë“œ"""
        tech = state["tech_name"]
        pi = state.get("first_item") or {}
        
        title = pi.get("title", "")
        abstract = pi.get("abstract", "")
        patent_id = (
            pi.get("publication_number") or 
            pi.get("patent_id") or 
            pi.get("id") or 
            "UNKNOWN"
        )
        
        rag_docs = state.get("retrieved_docs", [])
        web_results = state.get("web_search_results", [])
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        rag_text = ""
        for doc in rag_docs:
            if hasattr(doc, 'page_content'):
                rag_text += doc.page_content + "\n\n"
            elif isinstance(doc, dict):
                rag_text += doc.get('page_content', '') + "\n\n"
        rag_text = rag_text[:4000]
        
        web_text = ""
        for idx, result in enumerate(web_results[:6]):
            content = result.get("content", "")
            url = result.get("url", "")
            web_text += f"[Web Source {idx+1}] {url}\n{content[:500]}\n\n"
        
        sources = _collect_sources(rag_docs, web_results)

        system = (
            "ë„ˆëŠ” íŠ¹í—ˆ ìƒì—…í™” ë¶„ì„ ì „ë¬¸ê°€ë‹¤. "
            "íŠ¹í—ˆì˜ ì œëª©ê³¼ ì´ˆë¡ì„ **ì¤‘ì‹¬**ìœ¼ë¡œ ì‹œì¥ì„±ì„ í‰ê°€í•˜ë©°, "
            "RAG ë¬¸ì„œì™€ ì›¹ ê²€ìƒ‰ ê²°ê³¼ëŠ” **ì‹œì¥ ë°ì´í„° ì°¸ê³ ìš©**ìœ¼ë¡œë§Œ ì‚¬ìš©í•œë‹¤.\n\n"
            
            "## ì •ëŸ‰ì  ì ìˆ˜ ê¸°ì¤€\n\n"
            
            "### 1. market_size_score (0~0.4)\n"
            "íŠ¹í—ˆ ê¸°ìˆ ì´ **ì‹¤ì œë¡œ ì ìš© ê°€ëŠ¥í•œ ì„¸ë¶€ ì‹œì¥ ê·œëª¨(SAM)**ë¥¼ í‰ê°€:\n"
            "- 0.35~0.4: ì ìš© ê°€ëŠ¥ ì‹œì¥ $10B ì´ìƒ (ì—¬ëŸ¬ ì£¼ìš” ì œí’ˆêµ°ì— í•„ìˆ˜)\n"
            "  ì˜ˆ: LLM í›ˆë ¨ ì¸í”„ë¼ $12B, ììœ¨ì£¼í–‰ ì„¼ì„œ ì‹œì¥ $15B\n"
            "- 0.25~0.35: ì ìš© ê°€ëŠ¥ ì‹œì¥ $3B~$10B (íŠ¹ì • ì£¼ìš” ì œí’ˆêµ°ì˜ í•µì‹¬)\n"
            "  ì˜ˆ: ì¶”ì²œì‹œìŠ¤í…œ AI í•˜ë“œì›¨ì–´ $5B, ìŒì„±ì¸ì‹ ê°€ì† $4B\n"
            "- 0.15~0.25: ì ìš© ê°€ëŠ¥ ì‹œì¥ $1B~$3B (íŠ¹ì • Use Case ì§‘ì¤‘)\n"
            "  ì˜ˆ: íŠ¹ì • ëª¨ë¸ ìµœì í™” ì‹œì¥ $1.5B\n"
            "- 0.1~0.15: ì ìš© ê°€ëŠ¥ ì‹œì¥ $300M~$1B (í‹ˆìƒˆ ì‘ìš©)\n"
            "  ì˜ˆ: ì˜ë£Œ ì˜ìƒ ì „ìš© NPU $800M\n"
            "- 0.0~0.1: ì ìš© ê°€ëŠ¥ ì‹œì¥ $300M ë¯¸ë§Œ (ì‹¤í—˜ì /ì œí•œì )\n\n"
            
            "**ì¤‘ìš”**: ì „ì²´ ì‚°ì—… ê·œëª¨(ì˜ˆ: AI ë°˜ë„ì²´ $85B)ê°€ ì•„ë‹Œ, "
            "í•´ë‹¹ íŠ¹í—ˆ ê¸°ìˆ ì´ ì‹¤ì œ ì‚¬ìš©ë  êµ¬ì²´ì  ì„¸ë¶€ ì‹œì¥ì„ íŒë‹¨\n\n"
            
            "### 2. growth_potential_score (0~0.3)\n"
            "í•´ë‹¹ ì„¸ë¶€ ì‹œì¥ì˜ **CAGR ë˜ëŠ” êµ¬ì²´ì  ì„±ì¥ ìˆ˜ì¹˜**:\n"
            "- 0.25~0.3: CAGR 25%+ ë˜ëŠ” í–¥í›„ 5ë…„ê°„ 3ë°°+ ì„±ì¥\n"
            "  ì˜ˆ: '2025ë…„ 310ì–µ ë‹¬ëŸ¬ â†’ 2028ë…„ 602ì–µ ë‹¬ëŸ¬' (CAGR 25%)\n"
            "- 0.2~0.25: CAGR 20~25% ë˜ëŠ” 2ë°°+ ì„±ì¥\n"
            "- 0.15~0.2: CAGR 15~20% ë˜ëŠ” 1.5ë°°+ ì„±ì¥\n"
            "- 0.1~0.15: CAGR 10~15%\n"
            "- 0.0~0.1: CAGR 10% ë¯¸ë§Œ ë˜ëŠ” ì •ì²´\n\n"
            
            "**ì¤‘ìš”**: ì›¹ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ êµ¬ì²´ì  ìˆ˜ì¹˜(ì–µ/ì¡° ë‹¨ìœ„ í¬í•¨) ìš°ì„  í™œìš©\n\n"
            
            "### 3. commercialization_readiness (0~0.3)\n"
            "íŠ¹í—ˆ ê¸°ìˆ ì˜ **ìƒìš©í™” ê°€ëŠ¥ ì‹œì ê³¼ ì¤€ë¹„ë„**:\n"
            "- 0.25~0.3: ì¦‰ì‹œ~1ë…„ ë‚´ ì ìš© ê°€ëŠ¥, ëª…í™•í•œ ê³ ê°\n"
            "- 0.2~0.25: 1~2ë…„, í”„ë¡œí† íƒ€ì… ê²€ì¦ ì™„ë£Œ\n"
            "- 0.15~0.2: 2~3ë…„, íŒŒì¼ëŸ¿ ë‹¨ê³„\n"
            "- 0.1~0.15: 3~5ë…„, ì´ˆê¸° R&D\n"
            "- 0.0~0.1: 5ë…„+, ìƒì—…í™” ê²½ë¡œ ë¶ˆëª…í™•\n\n"
            
            "## market_rationale ì‘ì„± ê·œì¹™\n"
            "- ë°˜ë“œì‹œ 'ì´ íŠ¹í—ˆ({patent_id})ëŠ” ...'ë¡œ ì‹œì‘\n"
            "- 5~7ë¬¸ì¥, í•œ ë¬¸ë‹¨\n"
            "- íŠ¹í—ˆ ê¸°ìˆ  + ì ìš© ì‹œì¥ ê·œëª¨ + ì„±ì¥ë¥  + ìƒìš©í™” ì¤€ë¹„ë„ í†µí•© ì„¤ëª…\n"
            "- ì›¹ ê²€ìƒ‰ì—ì„œ ë°œê²¬í•œ êµ¬ì²´ì  ìˆ˜ì¹˜ ì¸ìš© (ì˜ˆ: '602ì–µ ë‹¬ëŸ¬', 'CAGR 11%')\n"
            "- ì¶”ì¸¡ ê¸ˆì§€, êµ¬ì²´ì  ê·¼ê±° ê¸°ë°˜\n\n"
            
            "ì¶œë ¥ì€ ë‹¨ì¼ JSON, sourcesëŠ” ì‘ì„±í•˜ì§€ ë§ ê²ƒ."
        )

        human = (
            "í‰ê°€ ëŒ€ìƒ:\n"
            "Patent ID: {patent_id}\n"
            "Title: {title}\n\n"
            "Abstract:\n{abstract}\n\n"
            "=== RAG ë¡œì»¬ ë¬¸ì„œ ===\n{rag}\n\n"
            "=== ì›¹ ê²€ìƒ‰ ê²°ê³¼ (Tavily) ===\n{web}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ëŸ‰ì  ì ìˆ˜ì™€ ì •ì„±ì  í‰ê°€ë¥¼ í¬í•¨í•œ JSONì„ ìƒì„±í•˜ë¼. "
            "íŠ¹íˆ ì›¹ ê²€ìƒ‰ ê²°ê³¼ì˜ êµ¬ì²´ì  ì‹œì¥ ê·œëª¨/ì„±ì¥ë¥  ìˆ˜ì¹˜ë¥¼ ìµœëŒ€í•œ í™œìš©í•  ê²ƒ."
        )

        prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human)])
        chain = prompt | self.llm.with_structured_output(_MarketSchema)

        try:
            output: _MarketSchema = chain.invoke({
                "patent_id": patent_id,
                "title": title,
                "abstract": abstract,
                "rag": rag_text,
                "web": web_text[:4000]
            })
            
            # âœ… Sourcesë¥¼ RAG + Tavilyë¡œ ë®ì–´ì“°ê¸°
            result = output.model_dump()
            result["sources"] = sources
            
            # market_score ê²€ì¦ ë° ì¬ê³„ì‚°
            calculated_score = (
                result["market_size_score"] + 
                result["growth_potential_score"] + 
                result["commercialization_readiness"]
            )
            result["market_score"] = round(calculated_score, 3)
            
            # MarketStateì— ê²°ê³¼ ì €ì¥
            state["patent_id"] = patent_id
            state["patent_title"] = title
            state["market_size_score"] = result["market_size_score"]
            state["growth_potential_score"] = result["growth_potential_score"]
            state["commercialization_readiness"] = result["commercialization_readiness"]
            state["market_score"] = result["market_score"]
            state["application_domains"] = result["application_domains"]
            state["commercialization_potential"] = result["commercialization_potential"]
            state["market_rationale"] = result["market_rationale"]
            state["demand_signals"] = result["demand_signals"]
            state["sources"] = sources
            
            print(f"  âœ… Evaluation complete:")
            print(f"     - Potential: {output.commercialization_potential}")
            print(f"     - Total Score: {result['market_score']:.3f}")
            print(f"     - Sources: {len(sources)} items")
            
        except Exception as e:
            print(f"  âŒ Synthesis failed: {e}")
            state["patent_id"] = patent_id
            state["patent_title"] = title
            state["error"] = str(e)
            state["market_score"] = 0.0
            state["sources"] = sources
        
        return state

    def evaluate_market(self) -> Dict[str, Any]:
        """ì‹œì¥ì„± í‰ê°€ ì‹¤í–‰"""
        print("=" * 80)
        print(f"ğŸš€ Patent Market Evaluation (RAG + Tavily): {self.tech_name}")
        print("=" * 80)

        title = self.patent_info.get("title", "")
        abstract = self.patent_info.get("abstract", "")
        
        # Abstractì—ì„œ í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ
        print("ğŸ“ Extracting key technical terms from abstract...")
        keyterms = _extract_keyterms_from_abstract(
            self.llm, title, abstract, max_terms=8
        )
        print(f"  âœ… Extracted keyterms: {keyterms}")
        
        # RAG ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        query = _build_rag_query(self.tech_name, keyterms)
        print(f"  ğŸ” RAG query: {query}")

        # State ì´ˆê¸°í™”
        init_state: MarketState = {
            "query": query,
            "tech_name": self.tech_name,
            "first_item": self.patent_info,  # MarketStateì˜ first_item í•„ë“œ ì‚¬ìš©
            "keyterms": keyterms,
            "retrieved_docs": [],
            "web_search_results": [],
        }

        # Graph ì‹¤í–‰
        final_state = self.graph.invoke(
            init_state,
            config={"configurable": {"thread_id": f"market-eval-{self.tech_name}"}}
        )

        # ê²°ê³¼ë¥¼ dictë¡œ ë³€í™˜
        result = {
            "tech_name": final_state.get("tech_name"),
            "patent_id": final_state.get("patent_id"),
            "patent_title": final_state.get("patent_title"),
            "market_size_score": final_state.get("market_size_score", 0.0),
            "growth_potential_score": final_state.get("growth_potential_score", 0.0),
            "commercialization_readiness": final_state.get("commercialization_readiness", 0.0),
            "market_score": final_state.get("market_score", 0.0),
            "application_domains": final_state.get("application_domains", []),
            "commercialization_potential": final_state.get("commercialization_potential", "Low"),
            "market_rationale": final_state.get("market_rationale", ""),
            "demand_signals": final_state.get("demand_signals", []),
            "sources": final_state.get("sources", []),
            "error": final_state.get("error"),
        }
        
        # ê²°ê³¼ ì €ì¥
        output_path = self._save(result)
        result["market_output_path"] = str(output_path)

        print("=" * 80)
        print("ğŸ“Š Final Market Evaluation Result")
        print("=" * 80)
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
        return result

    def _save(self, result: Dict[str, Any]) -> Path:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"market_eval_{self.tech_name}_{timestamp}.json"
        output_path = self.output_dir / filename
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Saved to: {output_path}")
        return output_path


# ===== CLI =====
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ì‹œì¥ì„± í‰ê°€ Agent (RAG + Tavily Web Search)"
    )
    parser.add_argument("tech_name", type=str, help="ê¸°ìˆ  í‚¤ì›Œë“œ (ì˜ˆ: NPU, AI accelerator)")
    parser.add_argument("--patent-json", type=str, required=True, help="íŠ¹í—ˆ ì •ë³´ JSON íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()

    # íŠ¹í—ˆ ì •ë³´ ë¡œë“œ
    with open(args.patent_json, "r", encoding="utf-8") as f:
        patent_data = json.load(f)
    
    first_patent = (patent_data.get("items") or [{}])[0]

    # Agent ì‹¤í–‰
    agent = MarketSizeGrowthAgent(args.tech_name, first_patent)
    agent.evaluate_market()